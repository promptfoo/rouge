{
  "version": 3,
  "sources": ["../src/rouge.ts", "../src/constants.ts", "../src/utils.ts"],
  "sourcesContent": ["/**\n * @license\n * @Author: Lim Mingjie, Kenneth\n * @Date:   2016-01-20T18:56:14-05:00\n * @Email:  me@kenlimmj.com\n * @Last modified by:   Astrianna\n * @Last modified time: 2016-02-27T19:50:25-05:00\n */\n\nimport * as utils from \"./utils\";\nexport * from \"./utils\";\n\n/**\n * Computes the ROUGE-N score for a candidate summary.\n *\n * Configuration object schema and defaults:\n * ```\n * {\n * \tn: 1                            // The size of the ngram used\n * \tnGram: <inbuilt function>,      // The ngram generator function\n * \ttokenizer: <inbuilt function>   // The string tokenizer\n * }\n * ```\n *\n * `nGram` has a type signature of ((Array<string>, number) => Array<string>)\n * `tokenizer` has a type signature of ((string) => Array<string)\n *\n * @method n\n * @param  {string}     cand        The candidate summary to be evaluated\n * @param  {string}     ref         The reference summary to be evaluated against\n * @param  {Object}     opts        Configuration options (see example)\n * @return {number}                 The ROUGE-N score\n */\nexport function n(\n  cand: string,\n  ref: string,\n  opts: {\n    n?: number;\n    nGram?: (tokens: string[], n: number) => string[];\n    tokenizer?: (input: string) => string[];\n  },\n): number {\n  if (cand.length === 0)\n    throw new RangeError(\"Candidate cannot be an empty string\");\n  if (ref.length === 0)\n    throw new RangeError(\"Reference cannot be an empty string\");\n\n  // Merge user-provided configuration with defaults\n  const options = Object.assign(\n    {\n      n: 1,\n      nGram: utils.nGram,\n      tokenizer: utils.treeBankTokenize,\n    },\n    opts,\n  );\n\n  const candGrams = options.nGram(options.tokenizer(cand), options.n);\n  const refGrams = options.nGram(options.tokenizer(ref), options.n);\n\n  const match = utils.intersection(candGrams, refGrams);\n  return match.length / refGrams.length;\n}\n\n/**\n * Computes the ROUGE-S score for a candidate summary.\n *\n * Configuration object schema and defaults:\n * ```\n * {\n * \tbeta: 1                             // The beta value used for the f-measure\n * \tgapLength: 2                        // The skip window\n * \tskipBigram: <inbuilt function>,     // The skip-bigram generator function\n * \ttokenizer: <inbuilt function>       // The string tokenizer\n * }\n * ```\n *\n * `skipBigram` has a type signature of ((Array<string>, number) => Array<string>)\n * `tokenizer` has a type signature of ((string) => Array<string)\n *\n * @method s\n * @param  {string}     cand        The candidate summary to be evaluated\n * @param  {string}     ref         The reference summary to be evaluated against\n * @param  {Object}     opts        Configuration options (see example)\n * @return {number}                 The ROUGE-S score\n */\nexport function s(\n  cand: string,\n  ref: string,\n  opts: {\n    beta?: number;\n    skipBigram?: (tokens: string[]) => string[];\n    tokenizer?: (input: string) => string[];\n  },\n): number {\n  if (cand.length === 0)\n    throw new RangeError(\"Candidate cannot be an empty string\");\n  if (ref.length === 0)\n    throw new RangeError(\"Reference cannot be an empty string\");\n\n  // Merge user-provided configuration with defaults\n  const options = Object.assign(\n    {\n      beta: 0.5,\n      skipBigram: utils.skipBigram,\n      tokenizer: utils.treeBankTokenize,\n    },\n    opts,\n  );\n\n  const candGrams = options.skipBigram(options.tokenizer(cand));\n  const refGrams = options.skipBigram(options.tokenizer(ref));\n\n  const skip2 = utils.intersection(candGrams, refGrams).length;\n\n  if (skip2 === 0) {\n    return 0;\n  } else {\n    const skip2Recall = skip2 / refGrams.length;\n    const skip2Prec = skip2 / candGrams.length;\n\n    return utils.fMeasure(skip2Prec, skip2Recall, options.beta);\n  }\n}\n\n/**\n * Computes the ROUGE-L score for a candidate summary\n *\n * Configuration object schema and defaults:\n * ```\n * {\n * \tbeta: 1                             // The beta value used for the f-measure\n * \tlcs: <inbuilt function>             // The least common subsequence function\n * \tsegmenter: <inbuilt function>,      // The sentence segmenter\n * \ttokenizer: <inbuilt function>       // The string tokenizer\n * }\n * ```\n *\n * `lcs` has a type signature of ((Array<string>, Array<string>) => Array<string>)\n * `segmenter` has a type signature of ((string) => Array<string)\n * `tokenizer` has a type signature of ((string) => Array<string)\n *\n * @method l\n * @param  {string}     cand        The candidate summary to be evaluated\n * @param  {string}     ref         The reference summary to be evaluated against\n * @param  {Object}     opts        Configuration options (see example)\n * @return {number}                 The ROUGE-L score\n */\nexport function l(\n  cand: string,\n  ref: string,\n  opts: {\n    beta?: number;\n    lcs?: (a: string[], b: string[]) => string[];\n    segmenter?: (input: string) => string[];\n    tokenizer?: (input: string) => string[];\n  },\n): number {\n  if (cand.length === 0)\n    throw new RangeError(\"Candidate cannot be an empty string\");\n  if (ref.length === 0)\n    throw new RangeError(\"Reference cannot be an empty string\");\n\n  // Merge user-provided configuration with defaults\n  const options = Object.assign(\n    {\n      beta: 0.5,\n      lcs: utils.lcs,\n      segmenter: utils.sentenceSegment,\n      tokenizer: utils.treeBankTokenize,\n    },\n    opts,\n  );\n\n  const candSents = options.segmenter(cand);\n  const refSents = options.segmenter(ref);\n\n  const candWords = options.tokenizer(cand);\n  const refWords = options.tokenizer(ref);\n\n  const lcsAcc = refSents.map((r) => {\n    const rTokens = options.tokenizer(r);\n    const lcsUnion = new Set(\n      ...candSents.map((c) => options.lcs(options.tokenizer(c), rTokens)),\n    );\n\n    return lcsUnion.size;\n  });\n\n  // Sum the array as quickly as we can\n  let lcsSum = 0;\n  while (lcsAcc.length) lcsSum += lcsAcc.pop() || 0;\n\n  const lcsRecall = lcsSum / candWords.length;\n  const lcsPrec = lcsSum / refWords.length;\n\n  return utils.fMeasure(lcsPrec, lcsRecall, options.beta);\n}\n", "/**\n * @Author: Lim Mingjie, Kenneth\n * @Date:   2016-01-20T19:03:19-05:00\n * @Email:  me@kenlimmj.com\n * @Last modified by:   Lim Mingjie, Kenneth\n * @Last modified time: 2016-01-26T23:22:24-05:00\n */\n\nexport const TREEBANK_CONTRACTIONS: RegExp[] = [\n  /\\b(can)(not)\\b/i,\n  /\\b(d)('ye)\\b/i,\n  /\\b(gim)(me)\\b/i,\n  /\\b(gon)(na)\\b/i,\n  /\\b(got)(ta)\\b/i,\n  /\\b(lem)(me)\\b/i,\n  /\\b(more)('n)\\b/i,\n  /\\b(wan)(na) /i,\n  /\\ ('t)(is)\\b/i,\n  /\\ ('t)(was)\\b/i,\n];\n\nexport const HONORIFICS: string[] = [\n  \"jr\",\n  \"mr\",\n  \"mrs\",\n  \"ms\",\n  \"dr\",\n  \"prof\",\n  \"sr\",\n  \"sen\",\n  \"corp\",\n  \"rep\",\n  \"gov\",\n  \"atty\",\n  \"supt\",\n  \"det\",\n  \"rev\",\n  \"col\",\n  \"gen\",\n  \"lt\",\n  \"cmdr\",\n  \"adm\",\n  \"capt\",\n  \"sgt\",\n  \"cpl\",\n  \"maj\",\n  \"miss\",\n  \"misses\",\n  \"mister\",\n  \"sir\",\n  \"esq\",\n  \"mstr\",\n  \"phd\",\n  \"adj\",\n  \"adv\",\n  \"asst\",\n  \"bldg\",\n  \"brig\",\n  \"comdr\",\n  \"hon\",\n  \"messrs\",\n  \"mlle\",\n  \"mme\",\n  \"op\",\n  \"ord\",\n  \"pvt\",\n  \"reps\",\n  \"res\",\n  \"sens\",\n  \"sfc\",\n  \"surg\",\n];\n\nexport const ABBR_COMMON: string[] = [\n  \"arc\",\n  \"al\",\n  \"exp\",\n  \"rd\",\n  \"st\",\n  \"dist\",\n  \"mt\",\n  \"fy\",\n  \"pd\",\n  \"pl\",\n  \"plz\",\n  \"tce\",\n  \"llb\",\n  \"md\",\n  \"bl\",\n  \"ma\",\n  \"ba\",\n  \"lit\",\n  \"ex\",\n  \"e.g\",\n  \"i.e\",\n  \"circa\",\n  \"ca\",\n  \"cca\",\n  \"v.s\",\n  \"etc\",\n  \"esp\",\n  \"ft\",\n  \"b.c\",\n  \"a.d\",\n];\n\nexport const ABBR_ORGANIZATIONS: string[] = [\n  \"co\",\n  \"corp\",\n  \"yahoo\",\n  \"joomla\",\n  \"jeopardy\",\n  \"dept\",\n  \"univ\",\n  \"assn\",\n  \"bros\",\n  \"inc\",\n  \"ltd\",\n];\n\nexport const ABBR_PLACES: string[] = [\n  \"ala\",\n  \"ariz\",\n  \"ark\",\n  \"cal\",\n  \"calif\",\n  \"col\",\n  \"colo\",\n  \"conn\",\n  \"del\",\n  \"fed\",\n  \"fla\",\n  \"fl\",\n  \"ga\",\n  \"ida\",\n  \"ind\",\n  \"ia\",\n  \"la\",\n  \"kan\",\n  \"kans\",\n  \"ken\",\n  \"ky\",\n  \"la\",\n  \"md\",\n  \"mich\",\n  \"minn\",\n  \"mont\",\n  \"neb\",\n  \"nebr\",\n  \"nev\",\n  \"okla\",\n  \"penna\",\n  \"penn\",\n  \"pa\",\n  \"dak\",\n  \"tenn\",\n  \"tex\",\n  \"ut\",\n  \"vt\",\n  \"va\",\n  \"wash\",\n  \"wis\",\n  \"wisc\",\n  \"wy\",\n  \"wyo\",\n  \"usafa\",\n  \"alta\",\n  \"ont\",\n  \"que\",\n  \"sask\",\n  \"yuk\",\n  \"ave\",\n  \"blvd\",\n  \"cl\",\n  \"ct\",\n  \"cres\",\n  \"hwy\",\n  \"U.S\",\n  \"U.S.A\",\n  \"E.U\",\n  \"N\u00B0\",\n];\n\nexport const ABBR_TIME: string[] = [\"a.m\", \"p.m\"];\n\nexport const ABBR_DATES: string[] = [\n  \"jan\",\n  \"feb\",\n  \"mar\",\n  \"apr\",\n  \"jun\",\n  \"jul\",\n  \"aug\",\n  \"sep\",\n  \"oct\",\n  \"nov\",\n  \"dec\",\n  \"sept\",\n  \"sep\",\n];\n\nexport const GATE_EXCEPTIONS: string[] = [\n  \"ex\",\n  \"e.g\",\n  \"i.e\",\n  \"circa\",\n  \"ca\",\n  \"cca\",\n  \"v.s\",\n  \"esp\",\n  \"ft\",\n  \"st\",\n  \"mt\",\n  ...HONORIFICS,\n];\n\nexport const GATE_SUBSTITUTIONS: string[] = [\n  ...ABBR_COMMON,\n  ...ABBR_DATES,\n  ...ABBR_ORGANIZATIONS,\n  ...ABBR_PLACES,\n  ...ABBR_TIME,\n  ...HONORIFICS,\n];\n", "/**\n * @license\n * @Author: Lim Mingjie, Kenneth\n * @Date:   2016-01-20T18:56:22-05:00\n * @Email:  me@kenlimmj.com\n * @Last modified by:   Astrianna\n * @Last modified time: 2016-02-27T21:34:23-05:00\n */\n\nimport {\n  GATE_SUBSTITUTIONS,\n  GATE_EXCEPTIONS,\n  TREEBANK_CONTRACTIONS,\n} from \"./constants\";\n\n/**\n * Splits a sentence into an array of word tokens\n * in accordance with the Penn Treebank guidelines.\n *\n * NOTE: This method assumes that the input is a single\n * sentence only. Providing multiple sentences within a\n * single string can trigger edge cases which have not\n * been accounted for.\n *\n * Adapted from Titus Wormer's port of the Penn Treebank Tokenizer\n * found at https://gist.github.com/wooorm/8504606\n *\n *\n * @method treeBankTokenize\n * @param  {string}           input     The sentence to be tokenized\n * @return {Array<string>}              An array of word tokens\n */\nexport function treeBankTokenize(input: string): string[] {\n  if (input.length === 0) return [];\n\n  // Does the following things in order of appearance by line:\n  // 1. Replace quotes at the sentence start position with double ticks\n  // 2. Wrap spaces around a double quote preceded by opening brackets\n  // 3. Wrap spaces around a non-unicode ellipsis\n  // 4. Wrap spaces around some punctuation signs (,;@#$%&)\n  // 5. Wrap spaces around a period and zero or more closing brackets\n  //    (or quotes), when not preceded by a period and when followed\n  //    by the end of the string. Only splits final periods because\n  //    sentence tokenization is assumed as a preprocessing step\n  // 6. Wrap spaces around all exclamation marks and question marks\n  // 7. Wrap spaces around opening and closing brackets\n  // 8. Wrap spaces around en and em-dashes\n  let parse = input\n    .replace(/^\\\"/, \" `` \")\n    .replace(/([ (\\[{<])\"/g, \"$1 `` \")\n    .replace(/\\.\\.\\.*/g, \" ... \")\n    .replace(/[;@#$%&]/g, \" $& \")\n    .replace(/([^\\.])(\\.)([\\]\\)}>\"\\']*)\\s*$/g, \"$1 $2$3 \")\n    .replace(/[,?!]/g, \" $& \")\n    .replace(/[\\]\\[\\(\\)\\{\\}<>]/g, \" $& \")\n    .replace(/---*/g, \" -- \");\n\n  // Wrap spaces at the start and end of the sentence for consistency\n  // i.e. reduce the number of Regex matches required\n  parse = ` ${parse} `;\n\n  // Does the following things in order of appearance by line:\n  // 1. Replace double quotes with a pair of single quotes wrapped with spaces\n  // 2. Wrap possessive or closing single quotes\n  // 3. Add a space before single quotes followed by `s`, `m`, or `d` and a space\n  // 4. Add a space before occurrences of `'ll`, `'re`, `'ve` or `n't`\n  parse = parse\n    .replace(/\"/g, \" '' \")\n    .replace(/([^'])' /g, \"$1 ' \")\n    .replace(/'([sSmMdD]) /g, \" '$1 \")\n    .replace(/('ll|'LL|'re|'RE|'ve|'VE|n't|N'T) /g, \" $1 \");\n\n  let iterator = -1;\n  while (iterator++ < TREEBANK_CONTRACTIONS.length) {\n    // Break uncommon contractions with a space and wrap-in spaces\n    parse = parse.replace(TREEBANK_CONTRACTIONS[iterator], \" $1 $2 \");\n  }\n\n  // Concatenate double spaces and remove start/end spaces\n  parse = parse.replace(/\\ \\ +/g, \" \").replace(/^\\ |\\ $/g, \"\");\n\n  // Split on spaces (original and inserted) to return the tokenized result\n  return parse.split(\" \");\n}\n\n/**\n * Splits a body of text into an array of sentences\n * using a rule-based segmentation approach.\n *\n * Adapted from Spencer Mountain's nlp_compromise library\n * found at https://github.com/spencermountain/nlp_compromise/\n *\n * @method sentenceSegment\n * @param  {string}         input     The document to be segmented\n * @return {Array<string>}            An array of sentences\n */\nexport function sentenceSegment(input: string): string[] {\n  if (input.length === 0) return [];\n\n  const abbrvReg = new RegExp(\n    \"\\\\b(\" + GATE_SUBSTITUTIONS.join(\"|\") + \")[.!?] ?$\",\n    \"i\",\n  );\n  const acronymReg = new RegExp(/[ |.][A-Z].?$/, \"i\");\n  const breakReg = new RegExp(/[\\r\\n]+/, \"g\");\n  const ellipseReg = new RegExp(/\\.\\.\\.*$/);\n  const excepReg = new RegExp(\n    \"\\\\b(\" + GATE_EXCEPTIONS.join(\"|\") + \")[.!?] ?$\",\n    \"i\",\n  );\n\n  // Split sentences naively based on common terminals (.?!\")\n  let chunks = input.split(/(\\S.+?[.?!])(?=\\s+|$|\")/g);\n\n  let acc: string[] = [];\n  for (let idx = 0; idx < chunks.length; idx++) {\n    if (chunks[idx]) {\n      // Trim only whitespace (i.e. preserve line breaks/carriage feeds)\n      chunks[idx] = chunks[idx].replace(/(^ +| +$)/g, \"\");\n\n      if (breakReg.test(chunks[idx])) {\n        if (chunks[idx + 1] && strIsTitleCase(chunks[idx])) {\n          // Catch line breaks embedded within valid sentences\n          // i.e. sentences that start with a capital letter\n          // and merge them with a delimiting space\n          chunks[idx + 1] =\n            (chunks[idx].trim() || \"\") +\n            \" \" +\n            (chunks[idx + 1] || \"\").replace(/ +/g, \" \");\n        } else {\n          // Assume that all other embedded line breaks are\n          // valid sentence breakpoints\n          acc.push(...chunks[idx].trim().split(\"\\n\"));\n        }\n      } else if (chunks[idx + 1] && abbrvReg.test(chunks[idx])) {\n        const nextChunk = chunks[idx + 1];\n        if (\n          nextChunk.trim() &&\n          strIsTitleCase(nextChunk) &&\n          !excepReg.test(chunks[idx])\n        ) {\n          // Catch abbreviations followed by a capital letter and treat as a boundary.\n          // FIXME: This causes named entities like `Mt. Fuji` or `U.S. Government` to fail.\n          acc.push(chunks[idx]);\n          chunks[idx] = \"\";\n        } else {\n          // Catch common abbreviations and merge them with a delimiting space\n          chunks[idx + 1] =\n            (chunks[idx] || \"\") + \" \" + (nextChunk || \"\").replace(/ +/g, \" \");\n        }\n      } else if (\n        chunks[idx].length > 1 &&\n        chunks[idx + 1] &&\n        acronymReg.test(chunks[idx])\n      ) {\n        const words = chunks[idx].split(\" \");\n        const lastWord = words[words.length - 1];\n\n        if (lastWord === lastWord.toLowerCase()) {\n          // Catch small-letter abbreviations and merge them.\n          chunks[idx + 1] = chunks[idx + 1] =\n            (chunks[idx] || \"\") +\n            \" \" +\n            (chunks[idx + 1] || \"\").replace(/ +/g, \" \");\n        } else if (chunks[idx + 2]) {\n          if (\n            strIsTitleCase(words[words.length - 2]) &&\n            strIsTitleCase(chunks[idx + 2])\n          ) {\n            // Catch name abbreviations (e.g. Albert I. Jones) by checking if\n            // the previous and next words are all capitalized.\n            chunks[idx + 2] =\n              (chunks[idx] || \"\") +\n              (chunks[idx + 1] || \"\").replace(/ +/g, \" \") +\n              (chunks[idx + 2] || \"\");\n          } else {\n            // Assume that remaining entities are indeed end-of-sentence markers.\n            acc.push(chunks[idx]);\n            chunks[idx] = \"\";\n          }\n        }\n      } else if (chunks[idx + 1] && ellipseReg.test(chunks[idx])) {\n        // Catch mid-sentence ellipses (and their derivatives) and merge them\n        chunks[idx + 1] =\n          (chunks[idx] || \"\") + (chunks[idx + 1] || \"\").replace(/ +/g, \" \");\n      } else if (chunks[idx] && chunks[idx].length > 0) {\n        acc.push(chunks[idx]);\n        chunks[idx] = \"\";\n      }\n    }\n  }\n\n  // If no matches were found, return the input treated as a single sentence\n  return acc.length === 0 ? [input] : acc;\n}\n\n/**\n * Checks if a string is titlecase\n * @method strIsTitleCase\n * @param  {string}   input       The string to be checked\n * @return {boolean}              True if the string is titlecase and false otherwise\n */\nexport function strIsTitleCase(input: string): boolean {\n  const firstChar = input.trim().slice(0, 1);\n  return charIsUpperCase(firstChar);\n}\n\n/**\n * Checks if a character is uppercase\n * @method charIsUpperCase\n * @param  {string}   input     The character to be tested\n * @return {boolean}            True if the character is uppercase and false otherwise.\n */\nexport function charIsUpperCase(input: string): boolean {\n  if (input.length !== 1)\n    throw new RangeError(\"Input should be a single character\");\n\n  const char = input.charCodeAt(0);\n  return char >= 65 && char <= 90;\n}\n\n/**\n * Memoizes a function using a Map\n *\n * @method memoize\n * @param  {Function} func    The function to be memoized\n * @param  {Function} Store   The data store constructor. Defaults to the ES6-inbuilt Map function.\n *                            A store should implement `has`, `get`, and `set` methods.\n * @return {Function}         A closure of the memoization cache and the original function\n */\nfunction memoize<T, R>(\n  func: (arg: T) => R,\n  Store: new () => Map<T, R> = Map,\n): (arg: T) => R {\n  return (() => {\n    let cache = new Store();\n\n    return (n: T) => {\n      if (cache.has(n)) {\n        return cache.get(n)!;\n      } else {\n        let result = func(n);\n        cache.set(n, result);\n        return result;\n      }\n    };\n  })();\n}\n\n/**\n * Computes the factorial of a number.\n *\n * This function uses a tail-recursive call to avoid\n * blowing the stack when computing inputs with a large\n * recursion depth.\n *\n * If this function will be called repeatedly within\n * the same scope, it is highly recommended that the\n * user memoize the function (e.g. lodash.memoize).\n *\n * @method factRec\n * @param  {number} x     The number for which the factorial is to be computed\n * @param  {number} acc   The starting value for the computation. Defaults to 1.\n * @return {number}       The factorial result\n */\nfunction factRec(x: number, acc: number = 1): number {\n  if (x < 0) throw RangeError(\"Input must be a positive number\");\n  return x < 2 ? acc : factRec(x - 1, x * acc);\n}\n\nexport const fact = memoize(factRec);\n\n/**\n * Returns the skip bigrams for an array of word tokens.\n *\n * @method skipBigram\n * @param  {Array<string>}    tokens      An array of word tokens\n * @return {Array<string>}                An array of skip bigram strings\n */\nexport function skipBigram(tokens: string[]): string[] {\n  if (tokens.length < 2)\n    throw new RangeError(\"Input must have at least two words\");\n\n  let acc: string[] = [];\n  for (let baseIdx = 0; baseIdx < tokens.length - 1; baseIdx++) {\n    for (let sweepIdx = baseIdx + 1; sweepIdx < tokens.length; sweepIdx++) {\n      acc.push(`${tokens[baseIdx]} ${tokens[sweepIdx]}`);\n    }\n  }\n\n  return acc;\n}\n\ninterface NGramOptions {\n  start: boolean;\n  end: boolean;\n  val: string;\n}\n\nexport const NGRAM_DEFAULT_OPTS: NGramOptions = {\n  start: false,\n  end: false,\n  val: \"<S>\",\n};\n\n/**\n * Returns n-grams for an array of word tokens.\n *\n * @method nGram\n * @param  {Array<string>}          tokens    An array of word tokens\n * @param  {number}                 n         The size of the n-gram. Defaults to 2.\n * @param  {Object}                 pad       String padding options. See example.\n * @return {Array<string>}                    An array of n-gram strings\n */\nexport function nGram(\n  tokens: string[],\n  n: number = 2,\n  pad: Partial<NGramOptions> = {},\n): string[] {\n  if (n < 1) throw new RangeError(\"ngram size cannot be smaller than 1\");\n\n  if (tokens.length < n) {\n    throw new RangeError(\n      \"ngram size cannot be larger than the number of tokens available\",\n    );\n  }\n\n  if (Object.keys(pad).length !== 0) {\n    const config = { ...NGRAM_DEFAULT_OPTS, ...pad };\n\n    // Clone the input token array to avoid mutating the source data\n    let tempTokens = tokens.slice(0);\n\n    if (config.start)\n      for (let i = 0; i < n - 1; i++) tempTokens.unshift(config.val);\n    if (config.end) for (let i = 0; i < n - 1; i++) tempTokens.push(config.val);\n\n    tokens = tempTokens;\n  }\n\n  let acc: string[] = [];\n  for (let idx = 0; idx < tokens.length - n + 1; idx++) {\n    acc.push(tokens.slice(idx, idx + n).join(\" \"));\n  }\n\n  return acc;\n}\n\n/**\n * Calculates C(val, 2), i.e. the number of ways 2\n * items can be chosen from `val` items.\n *\n * @method comb2\n * @param  {number} val     The total number of items to choose from\n * @return {number}         The number of ways in which 2 items can be chosen from `val`\n */\nexport function comb2(val: number): number {\n  if (val < 2) throw new RangeError(\"Input must be greater than 2\");\n  return 0.5 * val * (val - 1);\n}\n\n/**\n * Computes the arithmetic mean of an array\n * @method arithmeticMean\n * @param  {Array<number>}   input    Data distribution\n * @return {number}                   The mean of the distribution\n */\nexport function arithmeticMean(input: number[]): number {\n  if (input.length < 1)\n    throw new RangeError(\"Input array must have at least 1 element\");\n  return input.reduce((x, y) => x + y) / input.length;\n}\n\n/**\n * Evaluates the jackknife resampling result for a set of\n * candidate summaries vs. a reference summary.\n *\n * @method jackKnife\n * @param  {Array<string>}  cands      An array of candidate summaries to be evaluated\n * @param  {string}         ref        The reference summary to be evaluated against\n * @param  {Function}       func       The function used to evaluate a candidate against a reference.\n *                                     Should be of the type signature (string, string) => number\n * @param  {Function}       test       The function used to compute the test statistic.\n *                                     Defaults to the arithmetic mean.\n *                                     Should be of the type signature (Array<number>) => number\n * @return {number}                    The result computed by applying `test` to the resampled data\n */\nexport function jackKnife(\n  cands: string[],\n  ref: string,\n  func: (x: string, y: string) => number,\n  test: (x: number[]) => number = arithmeticMean,\n): number {\n  if (cands.length < 2) {\n    throw new RangeError(\"Candidate array must contain more than one element\");\n  }\n\n  const pairs: number[] = cands.map((c) => func(c, ref));\n\n  const acc: number[] = [];\n  for (let idx = 0; idx < pairs.length; idx++) {\n    // Clone the array and remove one element\n    const leaveOneOut = pairs.slice(0);\n    leaveOneOut.splice(idx, 1);\n\n    acc.push(Math.max(...leaveOneOut));\n  }\n\n  return test(acc);\n}\n\n/**\n * Calculates the ROUGE f-measure for a given precision\n * and recall score.\n *\n * DUC evaluation favors precision by setting beta to an\n * arbitrary large number. To replicate this, set beta to\n * any value larger than 1.\n *\n * @method fMeasure\n * @param  {number}     p       Precision score\n * @param  {number}     r       Recall score\n * @param  {number}     beta    Weighing value (precision vs. recall).\n *                              Defaults to 0.5, i.e. mean f-score\n * @return {number}             Computed f-score\n */\nexport function fMeasure(p: number, r: number, beta: number = 0.5): number {\n  if (p < 0 || p > 1)\n    throw new RangeError(\"Precision value p must have bounds 0 \u2264 p \u2264 1\");\n  if (r < 0 || r > 1)\n    throw new RangeError(\"Recall value r must have bounds 0 \u2264 r \u2264 1\");\n\n  if (beta < 0) {\n    throw new RangeError(\"beta value must be greater than 0\");\n  } else if (0 <= beta && beta <= 1) {\n    return ((1 + beta * beta) * r * p) / (r + beta * beta * p);\n  } else {\n    return r;\n  }\n}\n\n/**\n * Computes the set intersection of two arrays\n *\n * @method intersection\n * @param  {Array<string>}    a     The first array\n * @param  {Array<string>}    b     The second array\n * @return {Array<string>}          Elements common to both the first and second array\n */\nexport function intersection(a: string[], b: string[]): string[] {\n  const test = new Set(a);\n  const ref = new Set(b);\n\n  return Array.from(test).filter((elem) => ref.has(elem));\n}\n\n/**\n * Computes the longest common subsequence for two arrays.\n * This function returns the elements from the two arrays\n * that form the LCS, in order of their appearance.\n *\n * For speed, the search-space is pruned by eliminating\n * common entities at the start and end of both input arrays.\n *\n * @method lcs\n * @param  {Array<string>}    a     The first array\n * @param  {Array<string>}    b     The second array\n * @return {Array<string>}          The longest common subsequence between the first and second array\n */\nexport function lcs(a: string[], b: string[]): string[] {\n  if (a.length === 0 || b.length === 0) return [];\n\n  const dp: number[][] = Array(a.length + 1)\n    .fill(0)\n    .map(() => Array(b.length + 1).fill(0));\n\n  for (let i = 1; i <= a.length; i++) {\n    for (let j = 1; j <= b.length; j++) {\n      if (a[i - 1] === b[j - 1]) {\n        dp[i][j] = dp[i - 1][j - 1] + 1;\n      } else {\n        dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n      }\n    }\n  }\n\n  const lcsResult: string[] = [];\n  let i = a.length;\n  let j = b.length;\n\n  while (i > 0 && j > 0) {\n    if (a[i - 1] === b[j - 1]) {\n      lcsResult.unshift(a[i - 1]);\n      i--;\n      j--;\n    } else if (dp[i - 1][j] > dp[i][j - 1]) {\n      i--;\n    } else {\n      j--;\n    }\n  }\n\n  return lcsResult;\n}\n"],
  "mappings": "yaAAA,IAAAA,EAAA,GAAAC,EAAAD,EAAA,wBAAAE,EAAA,mBAAAC,EAAA,oBAAAC,EAAA,UAAAC,EAAA,aAAAC,EAAA,SAAAC,EAAA,iBAAAC,EAAA,cAAAC,EAAA,MAAAC,EAAA,QAAAC,EAAA,MAAAC,EAAA,UAAAC,EAAA,MAAAC,EAAA,oBAAAC,EAAA,eAAAC,EAAA,mBAAAC,EAAA,qBAAAC,IAAA,eAAAC,EAAAnB,GCQO,IAAMoB,EAAkC,CAC7C,kBACA,gBACA,iBACA,iBACA,iBACA,iBACA,kBACA,gBACA,gBACA,gBACF,EAEaC,EAAuB,CAClC,KACA,KACA,MACA,KACA,KACA,OACA,KACA,MACA,OACA,MACA,MACA,OACA,OACA,MACA,MACA,MACA,MACA,KACA,OACA,MACA,OACA,MACA,MACA,MACA,OACA,SACA,SACA,MACA,MACA,OACA,MACA,MACA,MACA,OACA,OACA,OACA,QACA,MACA,SACA,OACA,MACA,KACA,MACA,MACA,OACA,MACA,OACA,MACA,MACF,EAEaC,EAAwB,CACnC,MACA,KACA,MACA,KACA,KACA,OACA,KACA,KACA,KACA,KACA,MACA,MACA,MACA,KACA,KACA,KACA,KACA,MACA,KACA,MACA,MACA,QACA,KACA,MACA,MACA,MACA,MACA,KACA,MACA,KACF,EAEaC,EAA+B,CAC1C,KACA,OACA,QACA,SACA,WACA,OACA,OACA,OACA,OACA,MACA,KACF,EAEaC,EAAwB,CACnC,MACA,OACA,MACA,MACA,QACA,MACA,OACA,OACA,MACA,MACA,MACA,KACA,KACA,MACA,MACA,KACA,KACA,MACA,OACA,MACA,KACA,KACA,KACA,OACA,OACA,OACA,MACA,OACA,MACA,OACA,QACA,OACA,KACA,MACA,OACA,MACA,KACA,KACA,KACA,OACA,MACA,OACA,KACA,MACA,QACA,OACA,MACA,MACA,OACA,MACA,MACA,OACA,KACA,KACA,OACA,MACA,MACA,QACA,MACA,OACF,EAEaC,EAAsB,CAAC,MAAO,KAAK,EAEnCC,EAAuB,CAClC,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OACA,KACF,EAEaC,EAA4B,CACvC,KACA,MACA,MACA,QACA,KACA,MACA,MACA,MACA,KACA,KACA,KACA,GAAGN,CACL,EAEaO,EAA+B,CAC1C,GAAGN,EACH,GAAGI,EACH,GAAGH,EACH,GAAGC,EACH,GAAGC,EACH,GAAGJ,CACL,EC/LO,SAASQ,EAAiBC,EAAyB,CACxD,GAAIA,EAAM,SAAW,EAAG,MAAO,CAAC,EAchC,IAAIC,EAAQD,EACT,QAAQ,MAAO,MAAM,EACrB,QAAQ,eAAgB,QAAQ,EAChC,QAAQ,WAAY,OAAO,EAC3B,QAAQ,YAAa,MAAM,EAC3B,QAAQ,iCAAkC,UAAU,EACpD,QAAQ,SAAU,MAAM,EACxB,QAAQ,oBAAqB,MAAM,EACnC,QAAQ,QAAS,MAAM,EAI1BC,EAAQ,IAAIA,CAAK,IAOjBA,EAAQA,EACL,QAAQ,KAAM,MAAM,EACpB,QAAQ,YAAa,OAAO,EAC5B,QAAQ,gBAAiB,OAAO,EAChC,QAAQ,sCAAuC,MAAM,EAExD,IAAIC,EAAW,GACf,KAAOA,IAAaC,EAAsB,QAExCF,EAAQA,EAAM,QAAQE,EAAsBD,CAAQ,EAAG,SAAS,EAIlE,OAAAD,EAAQA,EAAM,QAAQ,SAAU,GAAG,EAAE,QAAQ,WAAY,EAAE,EAGpDA,EAAM,MAAM,GAAG,CACxB,CAaO,SAASG,EAAgBJ,EAAyB,CACvD,GAAIA,EAAM,SAAW,EAAG,MAAO,CAAC,EAEhC,IAAMK,EAAW,IAAI,OACnB,OAASC,EAAmB,KAAK,GAAG,EAAI,YACxC,GACF,EACMC,EAAa,IAAI,OAAO,gBAAiB,GAAG,EAC5CC,EAAW,IAAI,OAAO,UAAW,GAAG,EACpCC,EAAa,IAAI,OAAO,UAAU,EAClCC,EAAW,IAAI,OACnB,OAASC,EAAgB,KAAK,GAAG,EAAI,YACrC,GACF,EAGIC,EAASZ,EAAM,MAAM,0BAA0B,EAE/Ca,EAAgB,CAAC,EACrB,QAASC,EAAM,EAAGA,EAAMF,EAAO,OAAQE,IACrC,GAAIF,EAAOE,CAAG,EAIZ,GAFAF,EAAOE,CAAG,EAAIF,EAAOE,CAAG,EAAE,QAAQ,aAAc,EAAE,EAE9CN,EAAS,KAAKI,EAAOE,CAAG,CAAC,EACvBF,EAAOE,EAAM,CAAC,GAAKC,EAAeH,EAAOE,CAAG,CAAC,EAI/CF,EAAOE,EAAM,CAAC,GACXF,EAAOE,CAAG,EAAE,KAAK,GAAK,IACvB,KACCF,EAAOE,EAAM,CAAC,GAAK,IAAI,QAAQ,MAAO,GAAG,EAI5CD,EAAI,KAAK,GAAGD,EAAOE,CAAG,EAAE,KAAK,EAAE,MAAM;AAAA,CAAI,CAAC,UAEnCF,EAAOE,EAAM,CAAC,GAAKT,EAAS,KAAKO,EAAOE,CAAG,CAAC,EAAG,CACxD,IAAME,EAAYJ,EAAOE,EAAM,CAAC,EAE9BE,EAAU,KAAK,GACfD,EAAeC,CAAS,GACxB,CAACN,EAAS,KAAKE,EAAOE,CAAG,CAAC,GAI1BD,EAAI,KAAKD,EAAOE,CAAG,CAAC,EACpBF,EAAOE,CAAG,EAAI,IAGdF,EAAOE,EAAM,CAAC,GACXF,EAAOE,CAAG,GAAK,IAAM,KAAOE,GAAa,IAAI,QAAQ,MAAO,GAAG,CAEtE,SACEJ,EAAOE,CAAG,EAAE,OAAS,GACrBF,EAAOE,EAAM,CAAC,GACdP,EAAW,KAAKK,EAAOE,CAAG,CAAC,EAC3B,CACA,IAAMG,EAAQL,EAAOE,CAAG,EAAE,MAAM,GAAG,EAC7BI,EAAWD,EAAMA,EAAM,OAAS,CAAC,EAEnCC,IAAaA,EAAS,YAAY,EAEpCN,EAAOE,EAAM,CAAC,EAAIF,EAAOE,EAAM,CAAC,GAC7BF,EAAOE,CAAG,GAAK,IAChB,KACCF,EAAOE,EAAM,CAAC,GAAK,IAAI,QAAQ,MAAO,GAAG,EACnCF,EAAOE,EAAM,CAAC,IAErBC,EAAeE,EAAMA,EAAM,OAAS,CAAC,CAAC,GACtCF,EAAeH,EAAOE,EAAM,CAAC,CAAC,EAI9BF,EAAOE,EAAM,CAAC,GACXF,EAAOE,CAAG,GAAK,KACfF,EAAOE,EAAM,CAAC,GAAK,IAAI,QAAQ,MAAO,GAAG,GACzCF,EAAOE,EAAM,CAAC,GAAK,KAGtBD,EAAI,KAAKD,EAAOE,CAAG,CAAC,EACpBF,EAAOE,CAAG,EAAI,IAGpB,MAAWF,EAAOE,EAAM,CAAC,GAAKL,EAAW,KAAKG,EAAOE,CAAG,CAAC,EAEvDF,EAAOE,EAAM,CAAC,GACXF,EAAOE,CAAG,GAAK,KAAOF,EAAOE,EAAM,CAAC,GAAK,IAAI,QAAQ,MAAO,GAAG,EACzDF,EAAOE,CAAG,GAAKF,EAAOE,CAAG,EAAE,OAAS,IAC7CD,EAAI,KAAKD,EAAOE,CAAG,CAAC,EACpBF,EAAOE,CAAG,EAAI,IAMpB,OAAOD,EAAI,SAAW,EAAI,CAACb,CAAK,EAAIa,CACtC,CAQO,SAASE,EAAef,EAAwB,CACrD,IAAMmB,EAAYnB,EAAM,KAAK,EAAE,MAAM,EAAG,CAAC,EACzC,OAAOoB,EAAgBD,CAAS,CAClC,CAQO,SAASC,EAAgBpB,EAAwB,CACtD,GAAIA,EAAM,SAAW,EACnB,MAAM,IAAI,WAAW,oCAAoC,EAE3D,IAAMqB,EAAOrB,EAAM,WAAW,CAAC,EAC/B,OAAOqB,GAAQ,IAAMA,GAAQ,EAC/B,CAWA,SAASC,EACPC,EACAC,EAA6B,IACd,CACf,OAAQ,IAAM,CACZ,IAAIC,EAAQ,IAAID,EAEhB,OAAQE,GAAS,CACf,GAAID,EAAM,IAAIC,CAAC,EACb,OAAOD,EAAM,IAAIC,CAAC,EACb,CACL,IAAIC,EAASJ,EAAKG,CAAC,EACnB,OAAAD,EAAM,IAAIC,EAAGC,CAAM,EACZA,CACT,CACF,CACF,GAAG,CACL,CAkBA,SAASC,EAAQC,EAAWhB,EAAc,EAAW,CACnD,GAAIgB,EAAI,EAAG,MAAM,WAAW,iCAAiC,EAC7D,OAAOA,EAAI,EAAIhB,EAAMe,EAAQC,EAAI,EAAGA,EAAIhB,CAAG,CAC7C,CAEO,IAAMiB,EAAOR,EAAQM,CAAO,EAS5B,SAASG,EAAWC,EAA4B,CACrD,GAAIA,EAAO,OAAS,EAClB,MAAM,IAAI,WAAW,oCAAoC,EAE3D,IAAInB,EAAgB,CAAC,EACrB,QAASoB,EAAU,EAAGA,EAAUD,EAAO,OAAS,EAAGC,IACjD,QAASC,EAAWD,EAAU,EAAGC,EAAWF,EAAO,OAAQE,IACzDrB,EAAI,KAAK,GAAGmB,EAAOC,CAAO,CAAC,IAAID,EAAOE,CAAQ,CAAC,EAAE,EAIrD,OAAOrB,CACT,CAQO,IAAMsB,EAAmC,CAC9C,MAAO,GACP,IAAK,GACL,IAAK,KACP,EAWO,SAASC,EACdJ,EACA,EAAY,EACZK,EAA6B,CAAC,EACpB,CACV,GAAI,EAAI,EAAG,MAAM,IAAI,WAAW,qCAAqC,EAErE,GAAIL,EAAO,OAAS,EAClB,MAAM,IAAI,WACR,iEACF,EAGF,GAAI,OAAO,KAAKK,CAAG,EAAE,SAAW,EAAG,CACjC,IAAMC,EAAS,CAAE,GAAGH,EAAoB,GAAGE,CAAI,EAG3CE,EAAaP,EAAO,MAAM,CAAC,EAE/B,GAAIM,EAAO,MACT,QAASE,EAAI,EAAGA,EAAI,EAAI,EAAGA,IAAKD,EAAW,QAAQD,EAAO,GAAG,EAC/D,GAAIA,EAAO,IAAK,QAASE,EAAI,EAAGA,EAAI,EAAI,EAAGA,IAAKD,EAAW,KAAKD,EAAO,GAAG,EAE1EN,EAASO,CACX,CAEA,IAAI1B,EAAgB,CAAC,EACrB,QAASC,EAAM,EAAGA,EAAMkB,EAAO,OAAS,EAAI,EAAGlB,IAC7CD,EAAI,KAAKmB,EAAO,MAAMlB,EAAKA,EAAM,CAAC,EAAE,KAAK,GAAG,CAAC,EAG/C,OAAOD,CACT,CAUO,SAAS4B,EAAMC,EAAqB,CACzC,GAAIA,EAAM,EAAG,MAAM,IAAI,WAAW,8BAA8B,EAChE,MAAO,IAAMA,GAAOA,EAAM,EAC5B,CAQO,SAASC,EAAe3C,EAAyB,CACtD,GAAIA,EAAM,OAAS,EACjB,MAAM,IAAI,WAAW,0CAA0C,EACjE,OAAOA,EAAM,OAAO,CAAC6B,EAAGe,IAAMf,EAAIe,CAAC,EAAI5C,EAAM,MAC/C,CAgBO,SAAS6C,EACdC,EACAC,EACAxB,EACAyB,EAAgCL,EACxB,CACR,GAAIG,EAAM,OAAS,EACjB,MAAM,IAAI,WAAW,oDAAoD,EAG3E,IAAMG,EAAkBH,EAAM,IAAKI,GAAM3B,EAAK2B,EAAGH,CAAG,CAAC,EAE/ClC,EAAgB,CAAC,EACvB,QAASC,EAAM,EAAGA,EAAMmC,EAAM,OAAQnC,IAAO,CAE3C,IAAMqC,EAAcF,EAAM,MAAM,CAAC,EACjCE,EAAY,OAAOrC,EAAK,CAAC,EAEzBD,EAAI,KAAK,KAAK,IAAI,GAAGsC,CAAW,CAAC,CACnC,CAEA,OAAOH,EAAKnC,CAAG,CACjB,CAiBO,SAASuC,EAASC,EAAWC,EAAWC,EAAe,GAAa,CACzE,GAAIF,EAAI,GAAKA,EAAI,EACf,MAAM,IAAI,WAAW,wDAA8C,EACrE,GAAIC,EAAI,GAAKA,EAAI,EACf,MAAM,IAAI,WAAW,qDAA2C,EAElE,GAAIC,EAAO,EACT,MAAM,IAAI,WAAW,mCAAmC,EACnD,MAAI,IAAKA,GAAQA,GAAQ,GACrB,EAAIA,EAAOA,GAAQD,EAAID,GAAMC,EAAIC,EAAOA,EAAOF,GAEjDC,CAEX,CAUO,SAASE,EAAaC,EAAaC,EAAuB,CAC/D,IAAMV,EAAO,IAAI,IAAIS,CAAC,EAChBV,EAAM,IAAI,IAAIW,CAAC,EAErB,OAAO,MAAM,KAAKV,CAAI,EAAE,OAAQW,GAASZ,EAAI,IAAIY,CAAI,CAAC,CACxD,CAeO,SAASC,EAAIH,EAAaC,EAAuB,CACtD,GAAID,EAAE,SAAW,GAAKC,EAAE,SAAW,EAAG,MAAO,CAAC,EAE9C,IAAMG,EAAiB,MAAMJ,EAAE,OAAS,CAAC,EACtC,KAAK,CAAC,EACN,IAAI,IAAM,MAAMC,EAAE,OAAS,CAAC,EAAE,KAAK,CAAC,CAAC,EAExC,QAASlB,EAAI,EAAGA,GAAKiB,EAAE,OAAQjB,IAC7B,QAASsB,EAAI,EAAGA,GAAKJ,EAAE,OAAQI,IACzBL,EAAEjB,EAAI,CAAC,IAAMkB,EAAEI,EAAI,CAAC,EACtBD,EAAGrB,CAAC,EAAEsB,CAAC,EAAID,EAAGrB,EAAI,CAAC,EAAEsB,EAAI,CAAC,EAAI,EAE9BD,EAAGrB,CAAC,EAAEsB,CAAC,EAAI,KAAK,IAAID,EAAGrB,EAAI,CAAC,EAAEsB,CAAC,EAAGD,EAAGrB,CAAC,EAAEsB,EAAI,CAAC,CAAC,EAKpD,IAAMC,EAAsB,CAAC,EACzBvB,EAAIiB,EAAE,OACNK,EAAIJ,EAAE,OAEV,KAAOlB,EAAI,GAAKsB,EAAI,GACdL,EAAEjB,EAAI,CAAC,IAAMkB,EAAEI,EAAI,CAAC,GACtBC,EAAU,QAAQN,EAAEjB,EAAI,CAAC,CAAC,EAC1BA,IACAsB,KACSD,EAAGrB,EAAI,CAAC,EAAEsB,CAAC,EAAID,EAAGrB,CAAC,EAAEsB,EAAI,CAAC,EACnCtB,IAEAsB,IAIJ,OAAOC,CACT,CFtdO,SAASC,EACdC,EACAC,EACAC,EAKQ,CACR,GAAIF,EAAK,SAAW,EAClB,MAAM,IAAI,WAAW,qCAAqC,EAC5D,GAAIC,EAAI,SAAW,EACjB,MAAM,IAAI,WAAW,qCAAqC,EAG5D,IAAME,EAAU,OAAO,OACrB,CACE,EAAG,EACH,MAAaC,EACb,UAAiBC,CACnB,EACAH,CACF,EAEMI,EAAYH,EAAQ,MAAMA,EAAQ,UAAUH,CAAI,EAAGG,EAAQ,CAAC,EAC5DI,EAAWJ,EAAQ,MAAMA,EAAQ,UAAUF,CAAG,EAAGE,EAAQ,CAAC,EAGhE,OADoBK,EAAaF,EAAWC,CAAQ,EACvC,OAASA,EAAS,MACjC,CAwBO,SAASE,EACdT,EACAC,EACAC,EAKQ,CACR,GAAIF,EAAK,SAAW,EAClB,MAAM,IAAI,WAAW,qCAAqC,EAC5D,GAAIC,EAAI,SAAW,EACjB,MAAM,IAAI,WAAW,qCAAqC,EAG5D,IAAME,EAAU,OAAO,OACrB,CACE,KAAM,GACN,WAAkBO,EAClB,UAAiBL,CACnB,EACAH,CACF,EAEMI,EAAYH,EAAQ,WAAWA,EAAQ,UAAUH,CAAI,CAAC,EACtDO,EAAWJ,EAAQ,WAAWA,EAAQ,UAAUF,CAAG,CAAC,EAEpDU,EAAcH,EAAaF,EAAWC,CAAQ,EAAE,OAEtD,GAAII,IAAU,EACZ,MAAO,GACF,CACL,IAAMC,EAAcD,EAAQJ,EAAS,OAC/BM,EAAYF,EAAQL,EAAU,OAEpC,OAAaQ,EAASD,EAAWD,EAAaT,EAAQ,IAAI,CAC5D,CACF,CAyBO,SAASY,EACdf,EACAC,EACAC,EAMQ,CACR,GAAIF,EAAK,SAAW,EAClB,MAAM,IAAI,WAAW,qCAAqC,EAC5D,GAAIC,EAAI,SAAW,EACjB,MAAM,IAAI,WAAW,qCAAqC,EAG5D,IAAME,EAAU,OAAO,OACrB,CACE,KAAM,GACN,IAAWa,EACX,UAAiBC,EACjB,UAAiBZ,CACnB,EACAH,CACF,EAEMgB,EAAYf,EAAQ,UAAUH,CAAI,EAClCmB,EAAWhB,EAAQ,UAAUF,CAAG,EAEhCmB,EAAYjB,EAAQ,UAAUH,CAAI,EAClCqB,EAAWlB,EAAQ,UAAUF,CAAG,EAEhCqB,EAASH,EAAS,IAAKI,GAAM,CACjC,IAAMC,EAAUrB,EAAQ,UAAUoB,CAAC,EAKnC,OAJiB,IAAI,IACnB,GAAGL,EAAU,IAAKO,GAAMtB,EAAQ,IAAIA,EAAQ,UAAUsB,CAAC,EAAGD,CAAO,CAAC,CACpE,EAEgB,IAClB,CAAC,EAGGE,EAAS,EACb,KAAOJ,EAAO,QAAQI,GAAUJ,EAAO,IAAI,GAAK,EAEhD,IAAMK,EAAYD,EAASN,EAAU,OAC/BQ,EAAUF,EAASL,EAAS,OAElC,OAAaP,EAASc,EAASD,EAAWxB,EAAQ,IAAI,CACxD",
  "names": ["rouge_exports", "__export", "NGRAM_DEFAULT_OPTS", "arithmeticMean", "charIsUpperCase", "comb2", "fMeasure", "fact", "intersection", "jackKnife", "l", "lcs", "n", "nGram", "s", "sentenceSegment", "skipBigram", "strIsTitleCase", "treeBankTokenize", "__toCommonJS", "TREEBANK_CONTRACTIONS", "HONORIFICS", "ABBR_COMMON", "ABBR_ORGANIZATIONS", "ABBR_PLACES", "ABBR_TIME", "ABBR_DATES", "GATE_EXCEPTIONS", "GATE_SUBSTITUTIONS", "treeBankTokenize", "input", "parse", "iterator", "TREEBANK_CONTRACTIONS", "sentenceSegment", "abbrvReg", "GATE_SUBSTITUTIONS", "acronymReg", "breakReg", "ellipseReg", "excepReg", "GATE_EXCEPTIONS", "chunks", "acc", "idx", "strIsTitleCase", "nextChunk", "words", "lastWord", "firstChar", "charIsUpperCase", "char", "memoize", "func", "Store", "cache", "n", "result", "factRec", "x", "fact", "skipBigram", "tokens", "baseIdx", "sweepIdx", "NGRAM_DEFAULT_OPTS", "nGram", "pad", "config", "tempTokens", "i", "comb2", "val", "arithmeticMean", "y", "jackKnife", "cands", "ref", "test", "pairs", "c", "leaveOneOut", "fMeasure", "p", "r", "beta", "intersection", "a", "b", "elem", "lcs", "dp", "j", "lcsResult", "n", "cand", "ref", "opts", "options", "nGram", "treeBankTokenize", "candGrams", "refGrams", "intersection", "s", "skipBigram", "skip2", "skip2Recall", "skip2Prec", "fMeasure", "l", "lcs", "sentenceSegment", "candSents", "refSents", "candWords", "refWords", "lcsAcc", "r", "rTokens", "c", "lcsSum", "lcsRecall", "lcsPrec"]
}
